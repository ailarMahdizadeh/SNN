{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "debugged_finally-cap.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JT9eNm_QrpWM",
        "outputId": "3dc0a3dd-604c-49ff-e157-8a9efe46aa71"
      },
      "source": [
        "from google.colab import drive \n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8WpNogewxUt5"
      },
      "source": [
        "#utils\n",
        "import torch\n",
        "import torch.nn.functional as fn\n",
        "import numpy as np\n",
        "import math\n",
        "from torchvision import transforms\n",
        "from torchvision import datasets\n",
        "import os\n",
        "\n",
        "def to_pair(data):\n",
        "\tr\"\"\"Converts a single or a tuple of data into a pair. If the data is a tuple with more than two elements, it selects\n",
        "\tthe first two of them. In case of single data, it duplicates that data into a pair.\n",
        "\n",
        "\tArgs:\n",
        "\t\tdata (object or tuple): The input data.\n",
        "\n",
        "\tReturns:\n",
        "\t\tTuple: A pair of data.\n",
        "\t\"\"\"\n",
        "\tif isinstance(data, tuple):\n",
        "\t\treturn data[0:2]\n",
        "\treturn (data, data)\n",
        "\n",
        "def generate_inhibition_kernel(inhibition_percents):\n",
        "\tr\"\"\"Generates an inhibition kernel suitable to be used by :func:`~functional.intensity_lateral_inhibition`.\n",
        "\n",
        "\tArgs:\n",
        "\t\tinhibition_percents (sequence): The sequence of inhibition factors (in range [0,1]).\n",
        "\n",
        "\tReturns:\n",
        "\t\tTensor: Inhibition kernel.\n",
        "\t\"\"\"\n",
        "\tinhibition_kernel = torch.zeros(2*len(inhibition_percents)+1, 2*len(inhibition_percents)+1).float()\n",
        "\tcenter = len(inhibition_percents)\n",
        "\tfor i in range(2*len(inhibition_percents)+1):\n",
        "\t\tfor j in range(2*len(inhibition_percents)+1):\n",
        "\t\t\tdist = int(max(math.fabs(i - center), math.fabs(j - center)))\n",
        "\t\t\tif dist != 0:\n",
        "\t\t\t\tinhibition_kernel[i,j] = inhibition_percents[dist - 1]\n",
        "\treturn inhibition_kernel\n",
        "\n",
        "def tensor_to_text(data, address):\n",
        "\tr\"\"\"Saves a tensor into a text file in row-major format. The first line of the file contains comma-separated integers denoting\n",
        "\tthe size of each dimension. The second line contains comma-separated values indicating all the tensor's data.\n",
        "\n",
        "\tArgs:\n",
        "\t\tdata (Tensor): The tensor to be saved.\n",
        "\t\taddress (str): The saving address.\n",
        "\t\"\"\"\n",
        "\tf = open(address, \"w\")\n",
        "\tdata_cpu = data.cpu()\n",
        "\tshape = data.shape\n",
        "\tprint(\",\".join(map(str, shape)), file=f)\n",
        "\tdata_flat = data_cpu.view(-1).numpy()\n",
        "\tprint(\",\".join(data_flat.astype(np.str)), file=f)\n",
        "\tf.close()\n",
        "\n",
        "def text_to_tensor(address, type='float'):\n",
        "\tr\"\"\"Loads a tensor from a text file. Format of the text file is as follows: The first line of the file contains comma-separated integers denoting\n",
        "\tthe size of each dimension. The second line contains comma-separated values indicating all the tensor's data.\n",
        "\n",
        "\tArgs:\n",
        "\t\taddress (str): Address of the text file.\n",
        "\t\ttype (float or int, optional): The type of the tensor's data ('float' or 'int'). Default: 'float'\n",
        "\n",
        "\tReturns:\n",
        "\t\tTensor: The loaded tensor.\n",
        "\t\"\"\"\n",
        "\tf = open(address, \"r\")\n",
        "\tshape = tuple(map(int, f.readline().split(\",\")))\n",
        "\tdata = np.array(f.readline().split(\",\"))\n",
        "\tif type == 'float':\n",
        "\t\tdata = data.astype(np.float32)\n",
        "\telif type == 'int':\n",
        "\t\tdata = data.astype(np.int32)\n",
        "\telse:\n",
        "\t\traise ValueError(\"type must be 'int' or 'float'\")\n",
        "\tdata = torch.from_numpy(data)\n",
        "\tdata = data.reshape(shape)\n",
        "\tf.close()\n",
        "\treturn data\n",
        "\n",
        "class LateralIntencityInhibition:\n",
        "\tr\"\"\"Applies lateral inhibition on intensities. For each location, this inhibition decreases the intensity of the\n",
        "\tsurrounding cells that has lower intensities by a specific factor. This factor is relative to the distance of the\n",
        "\tneighbors and are put in the :attr:`inhibition_percents`.\n",
        "\n",
        "\tArgs:\n",
        "\t\tinhibition_percents (sequence): The sequence of inhibition factors (in range [0,1]).\n",
        "\t\"\"\"\n",
        "\tdef __init__(self, inhibition_percents):\n",
        "\t\tself.inhibition_kernel = generate_inhibition_kernel(inhibition_percents)\n",
        "\t\tself.inhibition_kernel.unsqueeze_(0).unsqueeze_(0)\n",
        "\n",
        "\t# decrease lateral intencities by factors given in the inhibition_kernel\n",
        "\tdef intensity_lateral_inhibition(self, intencities):\n",
        "\t\tintencities.squeeze_(0)\n",
        "\t\tintencities.unsqueeze_(1)\n",
        "\n",
        "\t\tinh_win_size = self.inhibition_kernel.size(-1)\n",
        "\t\trad = inh_win_size//2\n",
        "\t\t# repeat each value\n",
        "\t\tvalues = intencities.reshape(intencities.size(0),intencities.size(1),-1,1)\n",
        "\t\tvalues = values.repeat(1,1,1,inh_win_size)\n",
        "\t\tvalues = values.reshape(intencities.size(0),intencities.size(1),-1,intencities.size(-1)*inh_win_size)\n",
        "\t\tvalues = values.repeat(1,1,1,inh_win_size)\n",
        "\t\tvalues = values.reshape(intencities.size(0),intencities.size(1),-1,intencities.size(-1)*inh_win_size)\n",
        "\t\t# extend patches\n",
        "\t\tpadded = fn.pad(intencities,(rad,rad,rad,rad))\n",
        "\t\t# column-wise\n",
        "\t\tpatches = padded.unfold(-1,inh_win_size,1)\n",
        "\t\tpatches = patches.reshape(patches.size(0),patches.size(1),patches.size(2),-1,patches.size(3)*patches.size(4))\n",
        "\t\tpatches.squeeze_(-2)\n",
        "\t\t# row-wise\n",
        "\t\tpatches = patches.unfold(-2,inh_win_size,1).transpose(-1,-2)\n",
        "\t\tpatches = patches.reshape(patches.size(0),patches.size(1),1,-1,patches.size(-1))\n",
        "\t\tpatches.squeeze_(-3)\n",
        "\t\t# compare each element by its neighbors\n",
        "\t\tcoef = values - patches\n",
        "\t\tcoef.clamp_(min=0).sign_() # \"ones\" are neighbors greater than center\n",
        "\t\t# convolution with full stride to get accumulative inhibiiton factor\n",
        "\t\tfactors = fn.conv2d(coef, self.inhibition_kernel, stride=inh_win_size)\n",
        "\t\tresult = intencities + intencities * factors\n",
        "\n",
        "\t\tintencities.squeeze_(1)\n",
        "\t\tintencities.unsqueeze_(0)\n",
        "\t\tresult.squeeze_(1)\n",
        "\t\tresult.unsqueeze_(0)\n",
        "\t\treturn result\n",
        "\n",
        "\tdef __call__(self,input):\n",
        "\t\treturn self.intensity_lateral_inhibition(input)\n",
        "\n",
        "class FilterKernel:\n",
        "\tr\"\"\"Base class for generating image filter kernels such as Gabor, DoG, etc. Each subclass should override :attr:`__call__` function.\n",
        "\t\"\"\"\n",
        "\tdef __init__(self, window_size):\n",
        "\t\tself.window_size = window_size\n",
        "\n",
        "\tdef __call__(self):\n",
        "\t\tpass\n",
        "\n",
        "class DoGKernel(FilterKernel):\n",
        "\tr\"\"\"Generates DoG filter kernel.\n",
        "\n",
        "\tArgs:\n",
        "\t\twindow_size (int): The size of the window (square window).\n",
        "\t\tsigma1 (float): The sigma for the first Gaussian function.\n",
        "\t\tsigma2 (float): The sigma for the second Gaussian function.\n",
        "\t\"\"\"\n",
        "\tdef __init__(self, window_size, sigma1, sigma2):\n",
        "\t\tsuper(DoGKernel, self).__init__(window_size)\n",
        "\t\tself.sigma1 = sigma1\n",
        "\t\tself.sigma2 = sigma2\n",
        "\n",
        "\t# returns a 2d tensor corresponding to the requested DoG filter\n",
        "\tdef __call__(self):\n",
        "\t\tw = self.window_size//2\n",
        "\t\tx, y = np.mgrid[-w:w+1:1, -w:w+1:1]\n",
        "\t\ta = 1.0 / (2 * math.pi)\n",
        "\t\tprod = x*x + y*y\n",
        "\t\tf1 = (1/(self.sigma1*self.sigma1)) * np.exp(-0.5 * (1/(self.sigma1*self.sigma1)) * (prod))\n",
        "\t\tf2 = (1/(self.sigma2*self.sigma2)) * np.exp(-0.5 * (1/(self.sigma2*self.sigma2)) * (prod))\n",
        "\t\tdog = a * (f1-f2)\n",
        "\t\tdog_mean = np.mean(dog)\n",
        "\t\tdog = dog - dog_mean\n",
        "\t\tdog_max = np.max(dog)\n",
        "\t\tdog = dog / dog_max\n",
        "\t\tdog_tensor = torch.from_numpy(dog)\n",
        "\t\treturn dog_tensor.float()\n",
        "\n",
        "class GaborKernel(FilterKernel):\n",
        "\tr\"\"\"Generates Gabor filter kernel.\n",
        "\n",
        "\tArgs:\n",
        "\t\twindow_size (int): The size of the window (square window).\n",
        "\t\torientation (float): The orientation of the Gabor filter (in degrees).\n",
        "\t\tdiv (float, optional): The divisor of the lambda equation. Default: 4.0\n",
        "\t\"\"\"\n",
        "\tdef __init__(self, window_size, orientation, div=4.0):\n",
        "\t\tsuper(GaborKernel, self).__init__(window_size)\n",
        "\t\tself.orientation = orientation\n",
        "\t\tself.div = div\n",
        "\n",
        "\t# returns a 2d tensor corresponding to the requested Gabor filter\n",
        "\tdef __call__(self):\n",
        "\t\tw = self.window_size//2\n",
        "\t\tx, y = np.mgrid[-w:w+1:1, -w:w+1:1]\n",
        "\t\tlamda = self.window_size * 2 / self.div\n",
        "\t\tsigma = lamda * 0.8\n",
        "\t\tsigmaSq = sigma * sigma\n",
        "\t\tg = 0.3;\n",
        "\t\ttheta = (self.orientation * np.pi) / 180;\n",
        "\t\tY = y*np.cos(theta) - x*np.sin(theta)\n",
        "\t\tX = y*np.sin(theta) + x*np.cos(theta)\n",
        "\t\tgabor = np.exp(-(X * X + g * g * Y * Y) / (2 * sigmaSq)) * np.cos(2 * np.pi * X / lamda);\n",
        "\t\tgabor_mean = np.mean(gabor)\n",
        "\t\tgabor = gabor - gabor_mean\n",
        "\t\tgabor_max = np.max(gabor)\n",
        "\t\tgabor = gabor / gabor_max\n",
        "\t\tgabor_tensor = torch.from_numpy(gabor)\n",
        "\t\treturn gabor_tensor.float()\n",
        "\n",
        "class Filter:\n",
        "\tr\"\"\"Applies a filter transform. Each filter contains a sequence of :attr:`FilterKernel` objects.\n",
        "\tThe result of each filter kernel will be passed through a given threshold (if not :attr:`None`).\n",
        "\n",
        "\tArgs:\n",
        "\t\tfilter_kernels (sequence of FilterKernels): The sequence of filter kernels.\n",
        "\t\tpadding (int, optional): The size of the padding for the convolution of filter kernels. Default: 0\n",
        "\t\tthresholds (sequence of floats, optional): The threshold for each filter kernel. Default: None\n",
        "\t\tuse_abs (boolean, optional): To compute the absolute value of the outputs or not. Default: False\n",
        "\n",
        "\t.. note::\n",
        "\n",
        "\t\tThe size of the compund filter kernel tensor (stack of individual filter kernels) will be equal to the \n",
        "\t\tgreatest window size among kernels. All other smaller kernels will be zero-padded with an appropriate \n",
        "\t\tamount.\n",
        "\t\"\"\"\n",
        "\t# filter_kernels must be a list of filter kernels\n",
        "\t# thresholds must be a list of thresholds for each kernel\n",
        "\tdef __init__(self, filter_kernels, padding=0, thresholds=None, use_abs=False):\n",
        "\t\ttensor_list = []\n",
        "\t\tself.max_window_size = 0\n",
        "\t\tfor kernel in filter_kernels:\n",
        "\t\t\tif isinstance(kernel, torch.Tensor):\n",
        "\t\t\t\ttensor_list.append(kernel)\n",
        "\t\t\t\tself.max_window_size = max(self.max_window_size, kernel.size(-1))\n",
        "\t\t\telse:\n",
        "\t\t\t\ttensor_list.append(kernel().unsqueeze(0))\n",
        "\t\t\t\tself.max_window_size = max(self.max_window_size, kernel.window_size)\n",
        "\t\tfor i in range(len(tensor_list)):\n",
        "\t\t\tp = (self.max_window_size - filter_kernels[i].window_size)//2\n",
        "\t\t\ttensor_list[i] = fn.pad(tensor_list[i], (p,p,p,p))\n",
        "\n",
        "\t\tself.kernels = torch.stack(tensor_list)\n",
        "\t\tself.number_of_kernels = len(filter_kernels)\n",
        "\t\tself.padding = padding\n",
        "\t\tif isinstance(thresholds, list):\n",
        "\t\t\tself.thresholds = thresholds.clone().detach()\n",
        "\t\t\tself.thresholds.unsqueeze_(0).unsqueeze_(2).unsqueeze_(3)\n",
        "\t\telse:\n",
        "\t\t\tself.thresholds = thresholds\n",
        "\t\tself.use_abs = use_abs\n",
        "\n",
        "\t# returns a 4d tensor containing the flitered versions of the input image\n",
        "\t# input is a 4d tensor. dim: (minibatch=1, filter_kernels, height, width)\n",
        "\tdef __call__(self, input):\n",
        "\t\toutput = fn.conv2d(input, self.kernels, padding = self.padding).float()\n",
        "\t\tif not(self.thresholds is None):\n",
        "\t\t\toutput = torch.where(output < self.thresholds, torch.tensor(0.0, device=output.device), output)\n",
        "\t\tif self.use_abs:\n",
        "\t\t\ttorch.abs_(output)\n",
        "\t\treturn output\n",
        "\n",
        "class Intensity2Latency:\n",
        "\tr\"\"\"Applies intensity to latency transform. Spike waves are generated in the form of\n",
        "\tspike bins with almost equal number of spikes.\n",
        "\n",
        "\tArgs:\n",
        "\t\tnumber_of_spike_bins (int): Number of spike bins (time steps).\n",
        "\t\tto_spike (boolean, optional): To generate spike-wave tensor or not. Default: False\n",
        "\n",
        "\t.. note::\n",
        "\n",
        "\t\tIf :attr:`to_spike` is :attr:`False`, then the result is intesities that are ordered and packed into bins.\n",
        "\t\"\"\"\n",
        "\tdef __init__(self, number_of_spike_bins, to_spike=False):\n",
        "\t\tself.time_steps = number_of_spike_bins\n",
        "\t\tself.to_spike = to_spike\n",
        "\t\n",
        "\t# intencities is a tensor of input intencities (1, input_channels, height, width)\n",
        "\t# returns a tensor of tensors containing spikes in each timestep (considers minibatch for timesteps)\n",
        "\t# spikes are accumulative, i.e. spikes in timestep i are also presented in i+1, i+2, ...\n",
        "\tdef intensity_to_latency(self, intencities):\n",
        "\t\t#bins = []\n",
        "\t\tbins_intencities = []\n",
        "\t\tnonzero_cnt = torch.nonzero(intencities).size()[0]\n",
        "\n",
        "\t\t#check for empty bins\n",
        "\t\tbin_size = nonzero_cnt//self.time_steps\n",
        "\n",
        "\t\t#sort\n",
        "\t\tintencities_flattened = torch.reshape(intencities, (-1,))\n",
        "\t\tintencities_flattened_sorted = torch.sort(intencities_flattened, descending=True)\n",
        "\n",
        "\t\t#bin packing\n",
        "\t\tsorted_bins_value, sorted_bins_idx = torch.split(intencities_flattened_sorted[0], bin_size), torch.split(intencities_flattened_sorted[1], bin_size)\n",
        "\n",
        "\t\t#add to the list of timesteps\n",
        "\t\tspike_map = torch.zeros_like(intencities_flattened_sorted[0])\n",
        "\t\n",
        "\t\tfor i in range(self.time_steps):\n",
        "\t\t\tspike_map.scatter_(0, sorted_bins_idx[i], sorted_bins_value[i])\n",
        "\t\t\tspike_map_copy = spike_map.clone().detach()\n",
        "\t\t\tspike_map_copy = spike_map_copy.reshape(tuple(intencities.shape))\n",
        "\t\t\tbins_intencities.append(spike_map_copy.squeeze(0).float())\n",
        "\t\t\t#bins.append(spike_map_copy.sign().squeeze_(0).float())\n",
        "\t\n",
        "\t\treturn torch.stack(bins_intencities)#, torch.stack(bins)\n",
        "\t\t#return torch.stack(bins)\n",
        "\n",
        "\tdef __call__(self, image):\n",
        "\t\tif self.to_spike:\n",
        "\t\t\treturn self.intensity_to_latency(image).sign()\n",
        "\t\treturn self.intensity_to_latency(image)\n",
        "\n",
        "#class ImageFolderCache(datasets.ImageFolder):\n",
        "#\tdef __init__(self, root, transform=None, target_transform=None,\n",
        "#                 loader=datasets.folder.default_loader, cache_address=None):\n",
        "#\t\tsuper(ImageFolderCache, self).__init__(root, transform=transform, target_transform=target_transform, loader=loader)\n",
        "#\t\tself.imgs = self.samples\n",
        "#\t\tself.cache_address = cache_address\n",
        "#\t\tself.cache = [None] * len(self)\n",
        "\n",
        "#\tdef __getitem__(self, index):\n",
        "#\t\tpath, target = self.samples[index]\n",
        "#\t\tif self.cache[index] is None:\n",
        "#\t\t\tsample = self.loader(path)\n",
        "#\t\t\tif self.transform is not None:\n",
        "#\t\t\t\tsample = self.transform(sample)\n",
        "#\t\t\tif self.target_transform is not None:\n",
        "#\t\t\t\ttarget = self.target_transform(target)\n",
        "\n",
        "#\t\t\t#cache it\n",
        "#\t\t\tif self.cache_address is None:\n",
        "#\t\t\t\tself.cache[index] = sample\n",
        "#\t\t\telse:\n",
        "#\t\t\t\tsave_path = os.path.join(self.cache_address, str(index)+'.c')\n",
        "#\t\t\t\ttorch.save(sample, save_path)\n",
        "#\t\t\t\tself.cache[index] = save_path\n",
        "#\t\telse:\n",
        "#\t\t\tif self.cache_address is None:\n",
        "#\t\t\t\tsample = self.cache[index]\n",
        "#\t\t\telse:\n",
        "#\t\t\t\tsample = torch.load(self.cache[index])\n",
        "#\t\treturn sample, target\n",
        "\n",
        "#\tdef reset_cache(self):\n",
        "#\t\tself.cache = [None] * len(self)\n",
        "\n",
        "class CacheDataset(torch.utils.data.Dataset):\n",
        "\tr\"\"\"A wrapper dataset to cache pre-processed data. It can cache data on RAM or a secondary memory.\n",
        "\n",
        "\t.. note::\n",
        "\n",
        "\t\tSince converting image into spike-wave can be time consuming, we recommend to wrap your dataset into a :attr:`CacheDataset`\n",
        "\t\tobject.\n",
        "\n",
        "\tArgs:\n",
        "\t\tdataset (torch.utils.data.Dataset): The reference dataset object.\n",
        "\t\tcache_address (str, optional): The location of cache in the secondary memory. Use :attr:`None` to cache on RAM. Default: None\n",
        "\t\"\"\"\n",
        "\tdef __init__(self, dataset, cache_address=None):\n",
        "\t\tself.dataset = dataset\n",
        "\t\tself.cache_address = cache_address\n",
        "\t\tself.cache = [None] * len(self.dataset)\n",
        "\n",
        "\tdef __getitem__(self, index):\n",
        "\t\tif self.cache[index] is None:\n",
        "\t\t\t#cache it\n",
        "\t\t\tsample, target = self.dataset[index]\n",
        "\t\t\tif self.cache_address is None:\n",
        "\t\t\t\tself.cache[index] = sample, target\n",
        "\t\t\telse:\n",
        "\t\t\t\tsave_path = os.path.join(self.cache_address, str(index))\n",
        "\t\t\t\ttorch.save(sample, save_path + \".cd\")\n",
        "\t\t\t\ttorch.save(target, save_path + \".cl\")\n",
        "\t\t\t\tself.cache[index] = save_path\n",
        "\t\telse:\n",
        "\t\t\tif self.cache_address is None:\n",
        "\t\t\t\tsample, target = self.cache[index]\n",
        "\t\t\telse:\n",
        "\t\t\t\tsample = torch.load(self.cache[index] + \".cd\")\n",
        "\t\t\t\ttarget = torch.load(self.cache[index] + \".cl\")\n",
        "\t\treturn sample, target\n",
        "\n",
        "\tdef reset_cache(self):\n",
        "\t\tr\"\"\"Clears the cached data. It is useful when you want to change a pre-processing parameter during\n",
        "\t\tthe training process.\n",
        "\t\t\"\"\"\n",
        "\t\tif self.cache_address is not None:\n",
        "\t\t\tfor add in self.cache:\n",
        "\t\t\t\tos.remove(add + \".cd\")\n",
        "\t\t\t\tos.remove(add + \".cl\")\n",
        "\t\tself.cache = [None] * len(self)\n",
        "\n",
        "\tdef __len__(self):\n",
        "\t\treturn len(self.dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6YUYjKXTsaK-"
      },
      "source": [
        "# functional as sf\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as fn\n",
        "import numpy as np\n",
        "#from .utils import to_pair\n",
        "\n",
        "# padding\n",
        "# pad = (padLeft, padRight, padTop, padBottom)\n",
        "def pad(input, pad, value=0):\n",
        "\tr\"\"\"Applies 2D padding on the input tensor.\n",
        "\n",
        "\tArgs:\n",
        "\t\tinput (Tensor): The input tensor.\n",
        "\t\tpad (tuple): A tuple of 4 integers in the form of (padLeft, padRight, padTop, padBottom)\n",
        "\t\tvalue (int or float): The value of padding. Default: 0\n",
        "\n",
        "\tReturns:\n",
        "\t\tTensor: Padded tensor.\n",
        "\t\"\"\"\n",
        "\treturn fn.pad(input, pad, value=value)\n",
        "\n",
        "# pooling\n",
        "def pooling(input, kernel_size, stride=None, padding=0):\n",
        "\tr\"\"\"Performs a 2D max-pooling over an input signal (spike-wave or potentials) composed of several input\n",
        "\tplanes.\n",
        "\n",
        "\tArgs:\n",
        "\t\tinput (Tensor): The input tensor.\n",
        "\t\tkernel_size (int or tuple): Size of the pooling window.\n",
        "\t\tstride (int or tuple, optional): Stride of the pooling window. Default: None\n",
        "\t\tpadding (int or tuple, optional): Size of the padding. Default: 0\n",
        "\n",
        "\tReturns:\n",
        "\t\tTensor: The result of the max-pooling operation.\n",
        "\t\"\"\"\n",
        "\treturn fn.max_pool2d(input, kernel_size, stride, padding)\n",
        "\n",
        "def fire(potentials, threshold=None, return_thresholded_potentials=False):\n",
        "\tr\"\"\"Computes the spike-wave tensor from tensor of potentials. If :attr:`threshold` is :attr:`None`, all the neurons\n",
        "\temit one spike (if the potential is greater than zero) in the last time step.\n",
        "\n",
        "\tArgs:\n",
        "\t\tpotentials (Tensor): The tensor of input potentials.\n",
        "\t\tthreshold (float): Firing threshold. Default: None\n",
        "\t\treturn_thresholded_potentials (boolean): If True, the tensor of thresholded potentials will be returned\n",
        "\t\tas well as the tensor of spike-wave. Default: False\n",
        "\n",
        "\tReturns:\n",
        "\t\tTensor: Spike-wave tensor.\n",
        "\t\"\"\"\n",
        "\tthresholded = potentials.clone().detach()\n",
        "\tif threshold is None:\n",
        "\t\tthresholded[:-1]=0\n",
        "\telse:\n",
        "\t\tfn.threshold_(thresholded, threshold, 0)\n",
        "\tif return_thresholded_potentials:\n",
        "\t\treturn thresholded.sign(), thresholded\n",
        "\treturn thresholded.sign()\n",
        "\n",
        "def fire_(potentials, threshold=None):\n",
        "\tr\"\"\"The inplace version of :func:`~fire`\n",
        "\t\"\"\"\n",
        "\tif threshold is None:\n",
        "\t\tpotentials[:-1]=0\n",
        "\telse:\n",
        "\t\tfn.threshold_(potentials, threshold, 0)\n",
        "\tpotentials.sign_()\n",
        "\n",
        "def threshold(potentials, threshold=None):\n",
        "\tr\"\"\"Applies a threshold on potentials by which all of the values lower or equal to the threshold becomes zero.\n",
        "\tIf :attr:`threshold` is :attr:`None`, only the potentials corresponding to the final time step will survive.\n",
        "\n",
        "\tArgs:\n",
        "\t\tpotentials (Tensor): The tensor of input potentials.\n",
        "\t\tthreshold (float): The threshold value. Default: None\n",
        "\n",
        "\tReturns:\n",
        "\t\tTensor: Thresholded potentials.\n",
        "\t\"\"\"\n",
        "\toutputs = potentials.clone().detach()\n",
        "\tif threshold is None:\n",
        "\t\toutputs[:-1]=0\n",
        "\telse:\n",
        "\t\tfn.threshold_(outputs, threshold, 0)\n",
        "\treturn outputs\n",
        "\n",
        "def threshold_(potentials, threshold=None):\n",
        "\tr\"\"\"The inplace version of :func:`~threshold`\n",
        "\t\"\"\"\n",
        "\tif threshold is None:\n",
        "\t\tpotentials[:-1]=0\n",
        "\telse:\n",
        "\t\tfn.threshold_(potentials, threshold, 0)\n",
        "\n",
        "# in each position, the most fitted feature will survive (first earliest spike then maximum potential)\n",
        "# it is assumed that the threshold function is applied on the input potentials\n",
        "def pointwise_inhibition(thresholded_potentials):\n",
        "\tr\"\"\"Performs point-wise inhibition between feature maps. After inhibition, at most one neuron is allowed to fire at each\n",
        "\tposition, which is the neuron with the earliest spike time. If the spike times are the same, the neuron with the maximum\n",
        "\tpotential will be chosen. As a result, the potential of all of the inhibited neurons will be reset to zero.\n",
        "\n",
        "\tArgs:\n",
        "\t\tthresholded_potentials (Tensor): The tensor of thresholded input potentials.\n",
        "\n",
        "\tReturns:\n",
        "\t\tTensor: Inhibited potentials.\n",
        "\t\"\"\"\n",
        "\t# maximum of each position in each time step\n",
        "\tmaximum = torch.max(thresholded_potentials, dim=1, keepdim=True)\n",
        "\t# compute signs for detection of the earliest spike\n",
        "\tclamp_pot = maximum[0].sign()\n",
        "\t# maximum of clamped values is the indices of the earliest spikes\n",
        "\tclamp_pot_max_1 = (clamp_pot.size(0) - clamp_pot.sum(dim = 0, keepdim=True)).long()\n",
        "\tclamp_pot_max_1.clamp_(0,clamp_pot.size(0)-1)\n",
        "\tclamp_pot_max_0 = clamp_pot[-1:,:,:,:]\n",
        "\t# finding winners (maximum potentials between early spikes)\n",
        "\twinners = maximum[1].gather(0, clamp_pot_max_1)\n",
        "\t# generating inhibition coefficient\n",
        "\tcoef = torch.zeros_like(thresholded_potentials[0]).unsqueeze_(0)\n",
        "\tcoef.scatter_(1, winners,clamp_pot_max_0)\n",
        "\t# applying inhibition to potentials (broadcasting multiplication)\n",
        "\treturn torch.mul(thresholded_potentials, coef)\n",
        "\n",
        "# inhibiting particular features, preventing them to be winners\n",
        "# inhibited_features is a list of features numbers to be inhibited\n",
        "def feature_inhibition_(potentials, inhibited_features):\n",
        "\tr\"\"\"The inplace version of :func:`~feature_inhibition`\n",
        "\t\"\"\"\n",
        "\tif len(inhibited_features) != 0:\n",
        "\t\tpotentials[:, inhibited_features, :, :] = 0\n",
        "\n",
        "def feature_inhibition(potentials, inhibited_features):\n",
        "\tr\"\"\"Inhibits specified features (reset the corresponding neurons' potentials to zero).\n",
        "\n",
        "\tArgs:\n",
        "\t\tpotentials (Tensor): The tensor of input potentials.\n",
        "\t\tinhibited_features (List): The list of features to be inhibited.\n",
        "\n",
        "\tReturns:\n",
        "\t\tTensor: Inhibited potentials.\n",
        "\t\"\"\"\n",
        "\tpotentials_copy = potentials.clone().detach()\n",
        "\tif len(inhibited_features) != 0:\n",
        "\t\tfeature_inhibition_(potentials_copy, inhibited_features)\n",
        "\treturn potentials_copy\n",
        "\n",
        "# returns list of winners\n",
        "# inhibition_radius is to increase the chance of diversity among features (if needed)\n",
        "def get_k_winners(potentials, kwta = 1, inhibition_radius = 0, spikes = None):\n",
        "\tr\"\"\"Finds at most :attr:`kwta` winners first based on the earliest spike time, then based on the maximum potential.\n",
        "\tIt returns a list of winners, each in a tuple of form (feature, row, column).\n",
        "\n",
        "\t.. note::\n",
        "\n",
        "\t\tWinners are selected sequentially. Each winner inhibits surrounding neruons in a specific radius in all of the\n",
        "\t\tother feature maps. Note that only one winner can be selected from each feature map.\n",
        "\n",
        "\tArgs:\n",
        "\t\tpotentials (Tensor): The tensor of input potentials.\n",
        "\t\tkwta (int, optional): The number of winners. Default: 1\n",
        "\t\tinhibition_radius (int, optional): The radius of lateral inhibition. Default: 0\n",
        "\t\tspikes (Tensor, optional): Spike-wave corresponding to the input potentials. Default: None\n",
        "\n",
        "\tReturns:\n",
        "\t\tList: List of winners.\n",
        "\t\"\"\"\n",
        "\tif spikes is None:\n",
        "\t\tspikes = potentials.sign()\n",
        "\t# finding earliest potentials for each position in each feature\n",
        "\tmaximum = (spikes.size(0) - spikes.sum(dim = 0, keepdim=True)).long()\n",
        "\tmaximum.clamp_(0,spikes.size(0)-1)\n",
        "\tvalues = potentials.gather(dim=0, index=maximum) # gathering values\n",
        "\t# propagating the earliest potential through the whole timesteps\n",
        "\ttruncated_pot = spikes * values\n",
        "\t# summation with a high enough value (maximum of potential summation over timesteps) at spike positions\n",
        "\tv = truncated_pot.max() * potentials.size(0)\n",
        "\ttruncated_pot.addcmul_(spikes,v)\n",
        "\t# summation over all timesteps\n",
        "\ttotal = truncated_pot.sum(dim=0,keepdim=True)\n",
        "\t\n",
        "\ttotal.squeeze_(0)\n",
        "\tglobal_pooling_size = tuple(total.size())\n",
        "\twinners = []\n",
        "\tfor k in range(kwta):\n",
        "\t\tmax_val,max_idx = total.view(-1).max(0)\n",
        "\t\tif max_val.item() != 0:\n",
        "\t\t\t# finding the 3d position of the maximum value\n",
        "\t\t\tmax_idx_unraveled = np.unravel_index(max_idx.item(),global_pooling_size)\n",
        "\t\t\t# adding to the winners list\n",
        "\t\t\twinners.append(max_idx_unraveled)\n",
        "\t\t\t# preventing the same feature to be the next winner\n",
        "\t\t\ttotal[max_idx_unraveled[0],:,:] = 0\n",
        "\t\t\t# columnar inhibition (increasing the chance of leanring diverse features)\n",
        "\t\t\tif inhibition_radius != 0:\n",
        "\t\t\t\trowMin,rowMax = max(0,max_idx_unraveled[-2]-inhibition_radius),min(total.size(-2),max_idx_unraveled[-2]+inhibition_radius+1)\n",
        "\t\t\t\tcolMin,colMax = max(0,max_idx_unraveled[-1]-inhibition_radius),min(total.size(-1),max_idx_unraveled[-1]+inhibition_radius+1)\n",
        "\t\t\t\ttotal[:,rowMin:rowMax,colMin:colMax] = 0\n",
        "\t\telse:\n",
        "\t\t\tbreak\n",
        "\treturn winners\n",
        "\n",
        "# decrease lateral intencities by factors given in the inhibition_kernel\n",
        "def intensity_lateral_inhibition(intencities, inhibition_kernel):\n",
        "\tr\"\"\"Applies lateral inhibition on intensities. For each location, this inhibition decreases the intensity of the\n",
        "\tsurrounding cells that has lower intensities by a specific factor. This factor is relative to the distance of the\n",
        "\tneighbors and are put in the :attr:`inhibition_kernel`.\n",
        "\n",
        "\tArgs:\n",
        "\t\tintencities (Tensor): The tensor of input intensities.\n",
        "\t\tinhibition_kernel (Tensor): The tensor of inhibition factors.\n",
        "\n",
        "\tReturns:\n",
        "\t\tTensor: Inhibited intensities.\n",
        "\t\"\"\"\n",
        "\tintencities.squeeze_(0)\n",
        "\tintencities.unsqueeze_(1)\n",
        "\n",
        "\tinh_win_size = inhibition_kernel.size(-1)\n",
        "\trad = inh_win_size//2\n",
        "\t# repeat each value\n",
        "\tvalues = intencities.reshape(intencities.size(0),intencities.size(1),-1,1)\n",
        "\tvalues = values.repeat(1,1,1,inh_win_size)\n",
        "\tvalues = values.reshape(intencities.size(0),intencities.size(1),-1,intencities.size(-1)*inh_win_size)\n",
        "\tvalues = values.repeat(1,1,1,inh_win_size)\n",
        "\tvalues = values.reshape(intencities.size(0),intencities.size(1),-1,intencities.size(-1)*inh_win_size)\n",
        "\t# extend patches\n",
        "\tpadded = fn.pad(intencities,(rad,rad,rad,rad))\n",
        "\t# column-wise\n",
        "\tpatches = padded.unfold(-1,inh_win_size,1)\n",
        "\tpatches = patches.reshape(patches.size(0),patches.size(1),patches.size(2),-1,patches.size(3)*patches.size(4))\n",
        "\tpatches.squeeze_(-2)\n",
        "\t# row-wise\n",
        "\tpatches = patches.unfold(-2,inh_win_size,1).transpose(-1,-2)\n",
        "\tpatches = patches.reshape(patches.size(0),patches.size(1),1,-1,patches.size(-1))\n",
        "\tpatches.squeeze_(-3)\n",
        "\t# compare each element by its neighbors\n",
        "\tcoef = values - patches\n",
        "\tcoef.clamp_(min=0).sign_() # \"ones\" are neighbors greater than center\n",
        "\t# convolution with full stride to get accumulative inhibiiton factor\n",
        "\tfactors = fn.conv2d(coef, inhibition_kernel, stride=inh_win_size)\n",
        "\tresult = intencities + intencities * factors\n",
        "\n",
        "\tintencities.squeeze_(1)\n",
        "\tintencities.unsqueeze_(0)\n",
        "\tresult.squeeze_(1)\n",
        "\tresult.unsqueeze_(0)\n",
        "\treturn result\n",
        "\n",
        "# performs local normalization\n",
        "# on each region (of size radius*2 + 1) the mean value is computed and \n",
        "# intensities will be divided by the mean value\n",
        "# x is a 4D tensor\n",
        "def local_normalization(input, normalization_radius, eps=1e-12):\n",
        "\tr\"\"\"Applies local normalization. on each region (of size radius*2 + 1) the mean value is computed and the\n",
        "\tintensities will be divided by the mean value. The input is a 4D tensor.\n",
        "\n",
        "\tArgs:\n",
        "\t\tinput (Tensor): The input tensor of shape (timesteps, features, height, width).\n",
        "\t\tnormalization_radius (int): The radius of normalization window.\n",
        "\n",
        "\tReturns:\n",
        "\t\tTensor: Locally normalized tensor.\n",
        "\t\"\"\"\n",
        "\t# computing local mean by 2d convolution\n",
        "\tkernel = torch.ones(1,1,normalization_radius*2+1,normalization_radius*2+1,device=input.device).float()/((normalization_radius*2+1)**2)\n",
        "\t# rearrange 4D tensor so input channels will be considered as minibatches\n",
        "\ty = input.squeeze(0) # removes minibatch dim which was 1\n",
        "\ty.unsqueeze_(1)  # adds a dimension after channels so previous channels are now minibatches\n",
        "\tmeans = fn.conv2d(y,kernel,padding=normalization_radius) + eps # computes means\n",
        "\ty = y/means # normalization\n",
        "\t# swap minibatch with channels\n",
        "\ty.squeeze_(1)\n",
        "\ty.unsqueeze_(0)\n",
        "\treturn y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ta2Dy20tcI0"
      },
      "source": [
        "#snn\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as fn\n",
        "#from . import functional as sf\n",
        "from torch.nn.parameter import Parameter\n",
        "#from .utils import to_pair\n",
        "\n",
        "class Convolution(nn.Module):\n",
        "\tr\"\"\"Performs a 2D convolution over an input spike-wave composed of several input\n",
        "\tplanes. Current version only supports stride of 1 with no padding.\n",
        "\n",
        "\tThe input is a 4D tensor with the size :math:`(T, C_{{in}}, H_{{in}}, W_{{in}})` and the crresponsing output\n",
        "\tis of size :math:`(T, C_{{out}}, H_{{out}}, W_{{out}})`, \n",
        "\twhere :math:`T` is the number of time steps, :math:`C` is the number of feature maps (channels), and\n",
        "\t:math:`H`, and :math:`W` are the hight and width of the input/output planes.\n",
        "\n",
        "\t* :attr:`in_channels` controls the number of input planes (channels/feature maps).\n",
        "\n",
        "\t* :attr:`out_channels` controls the number of feature maps in the current layer.\n",
        "\n",
        "\t* :attr:`kernel_size` controls the size of the convolution kernel. It can be a single integer or a tuple of two integers.\n",
        "\n",
        "\t* :attr:`weight_mean` controls the mean of the normal distribution used for initial random weights.\n",
        "\n",
        "\t* :attr:`weight_std` controls the standard deviation of the normal distribution used for initial random weights.\n",
        "\n",
        "\t.. note::\n",
        "\n",
        "\t\tSince this version of convolution does not support padding, it is the user responsibility to add proper padding\n",
        "\t\ton the input before applying convolution.\n",
        "\n",
        "\tArgs:\n",
        "\t\tin_channels (int): Number of channels in the input.\n",
        "\t\tout_channels (int): Number of channels produced by the convolution.\n",
        "\t\tkernel_size (int or tuple): Size of the convolving kernel.\n",
        "\t\tweight_mean (float, optional): Mean of the initial random weights. Default: 0.8\n",
        "\t\tweight_std (float, optional): Standard deviation of the initial random weights. Default: 0.02\n",
        "\t\"\"\"\n",
        "\tdef __init__(self, in_channels, out_channels, kernel_size, weight_mean=0.8, weight_std=0.02):\n",
        "\t\tsuper(Convolution, self).__init__()\n",
        "\t\tself.in_channels = in_channels\n",
        "\t\tself.out_channels = out_channels\n",
        "\t\tself.kernel_size = to_pair(kernel_size)\n",
        "\t\t#self.weight_mean = weight_mean\n",
        "\t\t#self.weight_std = weight_std\n",
        "\n",
        "\t\t# For future use\n",
        "\t\tself.stride = 1\n",
        "\t\tself.bias = None\n",
        "\t\tself.dilation = 1\n",
        "\t\tself.groups = 1\n",
        "\t\tself.padding = 0\n",
        "\n",
        "\t\t# Parameters\n",
        "\t\tself.weight = Parameter(torch.Tensor(self.out_channels, self.in_channels, *self.kernel_size))\n",
        "\t\tself.weight.requires_grad_(False) # We do not use gradients\n",
        "\t\tself.reset_weight(weight_mean, weight_std)\n",
        "\n",
        "\tdef reset_weight(self, weight_mean=0.8, weight_std=0.02):\n",
        "\t\t\"\"\"Resets weights to random values based on a normal distribution.\n",
        "\n",
        "\t\tArgs:\n",
        "\t\t\tweight_mean (float, optional): Mean of the random weights. Default: 0.8\n",
        "\t\t\tweight_std (float, optional): Standard deviation of the random weights. Default: 0.02\n",
        "\t\t\"\"\"\n",
        "\t\tself.weight.normal_(weight_mean, weight_std)\n",
        "\n",
        "\tdef load_weight(self, target):\n",
        "\t\t\"\"\"Loads weights with the target tensor.\n",
        "\n",
        "\t\tArgs:\n",
        "\t\t\ttarget (Tensor=): The target tensor.\n",
        "\t\t\"\"\"\n",
        "\t\tself.weight.copy_(target)\t\n",
        "\n",
        "\tdef forward(self, input):\n",
        "\t\treturn fn.conv2d(input, self.weight, self.bias, self.stride, self.padding, self.dilation, self.groups)\n",
        "\n",
        "class Pooling(nn.Module):\n",
        "\tr\"\"\"Performs a 2D max-pooling over an input signal (spike-wave or potentials) composed of several input\n",
        "\tplanes.\n",
        "\n",
        "\t.. note::\n",
        "\n",
        "\t\tRegarding the structure of the spike-wave tensors, application of max-pooling over spike-wave tensors results\n",
        "\t\tin propagation of the earliest spike within each pooling window.\n",
        "\n",
        "\tThe input is a 4D tensor with the size :math:`(T, C, H_{{in}}, W_{{in}})` and the crresponsing output\n",
        "\tis of size :math:`(T, C, H_{{out}}, W_{{out}})`, \n",
        "\twhere :math:`T` is the number of time steps, :math:`C` is the number of feature maps (channels), and\n",
        "\t:math:`H`, and :math:`W` are the hight and width of the input/output planes.\n",
        "\n",
        "\t* :attr:`kernel_size` controls the size of the pooling window. It can be a single integer or a tuple of two integers.\n",
        "\n",
        "\t* :attr:`stride` controls the stride of the pooling. It can be a single integer or a tuple of two integers. If the value is None, it does pooling with full stride.\n",
        "\n",
        "\t* :attr:`padding` controls the amount of padding. It can be a single integer or a tuple of two integers.\n",
        "\n",
        "\tArgs:\n",
        "\t\tkernel_size (int or tuple): Size of the pooling window\n",
        "\t\tstride (int or tuple, optional): Stride of the pooling window. Default: None\n",
        "\t\tpadding (int or tuple, optional): Size of the padding. Default: 0\n",
        "\t\"\"\"\n",
        "\tdef __init__(self, kernel_size, stride=None, padding=0):\n",
        "\t\tsuper(Pooling, self).__init__()\n",
        "\t\tself.kernel_size = to_pair(kernel_size)\n",
        "\t\tif stride is None:\n",
        "\t\t\tself.stride = self.kernel_size\n",
        "\t\telse:\n",
        "\t\t\tself.stride = to_pair(stride)\n",
        "\t\tself.padding = to_pair(padding)\n",
        "\n",
        "\t\t# For future use\n",
        "\t\tself.dilation = 1\n",
        "\t\tself.return_indices = False\n",
        "\t\tself.ceil_mode = False\n",
        "\n",
        "\tdef forward(self, input):\n",
        "\t\treturn pooling(input, self.kernel_size, self.stride, self.padding) #\n",
        "\n",
        "class STDP(nn.Module):\n",
        "\tr\"\"\"Performs STDP learning rule over synapses of a convolutional layer based on the following formulation:\n",
        "\n",
        "\t.. math::\n",
        "\t\t\\Delta W_{ij}=\n",
        "\t\t\\begin{cases}\n",
        "\t\t\ta_{LTP}\\times \\left(W_{ij}-W_{LB}\\right)\\times \\left(W_{UP}-W_{ij}\\right) & \\ \\ \\ t_j - t_i \\leq 0,\\\\\n",
        "\t\t\ta_{LTD}\\times \\left(W_{ij}-W_{LB}\\right)\\times \\left(W_{UP}-W_{ij}\\right) & \\ \\ \\ t_j - t_i > 0,\\\\\n",
        "\t\t\\end{cases}\n",
        "\t\n",
        "\twhere :math:`i` and :math:`j` refer to the post- and pre-synaptic neurons, respectively,\n",
        "\t:math:`\\Delta w_{ij}` is the amount of weight change for the synapse connecting the two neurons,\n",
        "\tand :math:`a_{LTP}`, and :math:`a_{LTD}` scale the magnitude of weight change. Besides,\n",
        "\t:math:`\\left(W_{ij}-W_{LB}\\right)\\times \\left(W_{UP}-W_{ij}\\right)` is a stabilizer term which\n",
        "\tslowes down the weight change when the synaptic weight is close to the weight's lower (:math:`W_{LB}`)\n",
        "\tand upper (:math:`W_{UB}`) bounds.\n",
        "\n",
        "\tTo create a STDP object, you need to provide:\n",
        "\n",
        "\t* :attr:`conv_layer`: The convolutional layer on which the STDP should be applied.\n",
        "\n",
        "\t* :attr:`learning_rate`: (:math:`a_{LTP}`, :math:`a_{LTD}`) rates. A single pair of floats or a list of pairs of floats. Each feature map has its own learning rates.\n",
        "\n",
        "\t* :attr:`use_stabilizer`: Turns the stabilizer term on or off.\n",
        "\n",
        "\t* :attr:`lower_bound` and :attr:`upper_bound`: Control the range of weights.\n",
        "\n",
        "\tTo apply STDP for a particular stimulus, you need to provide:\n",
        "\t\n",
        "\t* :attr:`input_spikes` and :attr:`potentials` that are the input spike-wave and corresponding potentials, respectively.\n",
        "\n",
        "\t* :attr:`output_spikes` that is the output spike-wave.\n",
        "\n",
        "\t* :attr:`winners` or :attr:`kwta` to find winners based on the earliest spike then the maximum potential.\n",
        "\n",
        "\t* :attr:`inhibition_radius` to inhibit surrounding neurons (in all feature maps) within a particular radius.\n",
        "\n",
        "\tArgs:\n",
        "\t\tconv_layer (snn.Convolution): Reference convolutional layer.\n",
        "\t\tlearning_rate (tuple of floats or list of tuples of floats): (LTP, LTD) rates for STDP.\n",
        "\t\tuse_stabilizer (boolean, optional): Turning stabilizer term on or off. Default: True\n",
        "\t\tlower_bound (float, optional): Lower bound of the weight range. Default: 0\n",
        "\t\tupper_bound (float, optional): Upper bound of the weight range. Default: 1\n",
        "\t\"\"\"\n",
        "\tdef __init__(self, conv_layer, learning_rate, use_stabilizer = True, lower_bound = 0, upper_bound = 1):\n",
        "\t\tsuper(STDP, self).__init__()\n",
        "\t\tself.conv_layer = conv_layer\n",
        "\t\tif isinstance(learning_rate, list):\n",
        "\t\t\tself.learning_rate = learning_rate\n",
        "\t\telse:\n",
        "\t\t\tself.learning_rate = [learning_rate] * conv_layer.out_channels\n",
        "\t\tfor i in range(conv_layer.out_channels):\n",
        "\t\t\tself.learning_rate[i] = (Parameter(torch.tensor([self.learning_rate[i][0]])),\n",
        "\t\t\t\t\t\t\tParameter(torch.tensor([self.learning_rate[i][1]])))\n",
        "\t\t\tself.register_parameter('ltp_' + str(i), self.learning_rate[i][0])\n",
        "\t\t\tself.register_parameter('ltd_' + str(i), self.learning_rate[i][1])\n",
        "\t\t\tself.learning_rate[i][0].requires_grad_(False)\n",
        "\t\t\tself.learning_rate[i][1].requires_grad_(False)\n",
        "\t\tself.use_stabilizer = use_stabilizer\n",
        "\t\tself.lower_bound = lower_bound\n",
        "\t\tself.upper_bound = upper_bound\n",
        "\n",
        "\tdef get_pre_post_ordering(self, input_spikes, output_spikes, winners):\n",
        "\t\tr\"\"\"Computes the ordering of the input and output spikes with respect to the position of each winner and\n",
        "\t\treturns them as a list of boolean tensors. True for pre-then-post (or concurrency) and False for post-then-pre.\n",
        "\t\tInput and output tensors must be spike-waves.\n",
        "\n",
        "\t\tArgs:\n",
        "\t\t\tinput_spikes (Tensor): Input spike-wave\n",
        "\t\t\toutput_spikes (Tensor): Output spike-wave\n",
        "\t\t\twinners (List of Tuples): List of winners. Each tuple denotes a winner in a form of a triplet (feature, row, column).\n",
        "\n",
        "\t\tReturns:\n",
        "\t\t\tList: pre-post ordering of spikes\n",
        "\t\t\"\"\"\n",
        "\t\t# accumulating input and output spikes to get latencies\n",
        "\t\tinput_latencies = torch.sum(input_spikes, dim=0)\n",
        "\t\toutput_latencies = torch.sum(output_spikes, dim=0)\n",
        "\t\tresult = []\n",
        "\t\tfor winner in winners:\n",
        "\t\t\t# generating repeated output tensor with the same size of the receptive field\n",
        "\t\t\tout_tensor = torch.ones(*self.conv_layer.kernel_size, device=output_latencies.device) * output_latencies[winner]\n",
        "\t\t\t# slicing input tensor with the same size of the receptive field centered around winner\n",
        "\t\t\t# since there is no padding, there is no need to shift it to the center\n",
        "\t\t\tin_tensor = input_latencies[:,winner[-2]:winner[-2]+self.conv_layer.kernel_size[-2],winner[-1]:winner[-1]+self.conv_layer.kernel_size[-1]]\n",
        "\t\t\tresult.append(torch.ge(in_tensor,out_tensor))\n",
        "\t\treturn result\n",
        "\n",
        "\t# simple STDP rule\n",
        "\t# gets prepost pairings, winners, weights, and learning rates (all shoud be tensors)\n",
        "\tdef forward(self, input_spikes, potentials, output_spikes, winners=None, kwta = 1, inhibition_radius = 0):\n",
        "\t\tif winners is None:\n",
        "\t\t\twinners = get_k_winners(potentials, kwta, inhibition_radius, output_spikes) #sf\n",
        "\t\tpairings = self.get_pre_post_ordering(input_spikes, output_spikes, winners)\n",
        "\t\t\n",
        "\t\tlr = torch.zeros_like(self.conv_layer.weight)\n",
        "\t\tfor i in range(len(winners)):\n",
        "\t\t\tf = winners[i][0]\n",
        "\t\t\tlr[f] = torch.where(pairings[i], *(self.learning_rate[f]))\n",
        "\n",
        "\t\tself.conv_layer.weight += lr * ((self.conv_layer.weight-self.lower_bound) * (self.upper_bound-self.conv_layer.weight) if self.use_stabilizer else 1)\n",
        "\t\tself.conv_layer.weight.clamp_(self.lower_bound, self.upper_bound)\n",
        "\n",
        "\tdef update_learning_rate(self, feature, ap, an):\n",
        "\t\tr\"\"\"Updates learning rate for a specific feature map.\n",
        "\n",
        "        Args:\n",
        "            feature (int): The target feature.\n",
        "\t\t\tap (float): LTP rate.\n",
        "\t\t\tan (float): LTD rate.\n",
        "\t\t\"\"\"\n",
        "\t\tself.learning_rate[feature][0][0] = ap\n",
        "\t\tself.learning_rate[feature][1][0] = an\n",
        "\n",
        "\tdef update_all_learning_rate(self, ap, an):\n",
        "\t\tr\"\"\"Updates learning rates of all the feature maps to a same value.\n",
        "\n",
        "        Args:\n",
        "\t\t\tap (float): LTP rate.\n",
        "\t\t\tan (float): LTD rate.\n",
        "\t\t\"\"\"\n",
        "\t\tfor feature in range(self.conv_layer.out_channels):\n",
        "\t\t\tself.learning_rate[feature][0][0] = ap\n",
        "\t\t\tself.learning_rate[feature][1][0] = an"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HpWhGXYsztnI"
      },
      "source": [
        "#vis\n",
        "import torch\n",
        "from   PIL import Image\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "\n",
        "# Show 2D the tensor.\n",
        "def show_tensor(aTensor, _vmin = None, _vmax = None):\n",
        "\tr\"\"\"Plots a 2D tensor in gray color map and shows it in a window.\n",
        "\n",
        "\tArgs:\n",
        "\t\taTensor (Tensor): The input tensor.\n",
        "\t\t_vmin (float, optional): Minimum value. Default: None\n",
        "\t\t_vmax (float, optional): Maximum value. Default: None\n",
        "\n",
        "\t.. note::\n",
        "\n",
        "\t\t:attr:`None` for :attr:`_vmin` or :attr:`_vmin` causes an auto-scale mode for each.\n",
        "\t\"\"\"\n",
        "\tif aTensor.is_cuda:\n",
        "\t\taTensor = aTensor.cpu()\n",
        "\tplt.figure()\n",
        "\tplt.imshow(aTensor.numpy(),cmap='gray', vmin=_vmin, vmax=_vmax)\n",
        "\tplt.colorbar()\n",
        "\tplt.show()\n",
        "\n",
        "def plot_tensor_in_image(fname, aTensor, _vmin = None, _vmax = None):\n",
        "\tr\"\"\"Plots a 2D tensor in gray color map in an image file.\n",
        "\n",
        "\tArgs:\n",
        "\t\tfname (str): The file name.\n",
        "\t\taTensor (Tensor): The input tensor.\n",
        "\t\t_vmin (float, optional): Minimum value. Default: None\n",
        "\t\t_vmax (float, optional): Maximum value. Default: None\n",
        "\n",
        "\t.. note::\n",
        "\n",
        "\t\t:attr:`None` for :attr:`_vmin` or :attr:`_vmin` causes an auto-scale mode for each.\n",
        "\t\"\"\"\n",
        "\tif aTensor.is_cuda:\n",
        "\t\taTensor = aTensor.cpu()\n",
        "\tplt.imsave(fname,aTensor.numpy(),cmap='gray', vmin=_vmin, vmax=_vmax)\n",
        "\n",
        "# Computes window size of a neuron on specific previous layer\n",
        "# layer_details must be a sequence of quaraples containing (height, width, row_stride, col_stride)\n",
        "# of each layer\n",
        "def get_deep_receptive_field(*layers_details):\n",
        "\th,w = 1,1\n",
        "\tfor height,width,r_stride,c_stride in reversed(layers_details):\n",
        "\t\th = height + (h-1) * r_stride\n",
        "\t\tw = width + (w-1) * c_stride\n",
        "\treturn h,w\n",
        "\n",
        "# Computes the feature that a neuron is selective to given the feature of the neurons underneath\n",
        "# The cumulative stride (which is cumulative product of previous layers' strides) must be given\n",
        "# The stride of the previous layer must be given\n",
        "# pre_feature is the 3D tensor of the features for underlying neurons\n",
        "# feature_stride is the cumulative stride (tuple) = (height, width)\n",
        "# stride is the stride of previous layer (tuple) = (height, width)\n",
        "# weights is the 4D weight tensor of current layer (None if it is a pooling layer)\n",
        "# retruns features and the new cumulative stride\n",
        "def get_deep_feature(pre_feature, feature_stride, window_size, stride, weights=None):\n",
        "\tnew_cstride = (feature_stride[0] * stride[0], feature_stride[1] * stride[1])\n",
        "\tnew_size = (pre_feature.size(-2) + (window_size[0]-1) * feature_stride[0],\n",
        "\t\t\t pre_feature.size(-1) + (window_size[1]-1) * feature_stride[1])\n",
        "\tdepth = pre_feature.size(-3)\n",
        "\tif weights is not None:\n",
        "\t\tdepth = weights.size(0)\n",
        "\tnew_feature = torch.zeros(depth, *new_size, device=pre_feature.device)\n",
        "\tif weights is None: # place the feature in the middle of the field\n",
        "\t\tstart_point = (new_size[0]//2-pre_feature.size(-2)//2,new_size[1]//2-pre_feature.size(-1)//2)\n",
        "\t\tnew_feature[:,start_point[0]:start_point[0]+pre_feature.size(-2),start_point[1]:start_point[1]+pre_feature.size(-1)] = pre_feature\n",
        "\telse:\n",
        "\t\tfor r in range(weights.size(-2)): #rows\n",
        "\t\t\tfor c in range(weights.size(-1)): #cols\n",
        "\t\t\t\ttemp_features = pre_feature * weights[:,:,r:r+1,c:c+1]\n",
        "\t\t\t\ttemp_features = temp_features.max(dim=1)[0]\n",
        "\t\t\t\tnew_feature[:,r*feature_stride[0]:r*feature_stride[0]+pre_feature.size(-2),\n",
        "\t\t\t\tc*feature_stride[1]:c*feature_stride[1]+pre_feature.size(-1)] += temp_features\n",
        "\t\tnew_feature.clamp_(min=0) # removing negatives\n",
        "\n",
        "\treturn new_feature,new_cstride"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DIkZzDD19en6",
        "outputId": "00123786-509c-44d9-e4c5-cc4453913cb1"
      },
      "source": [
        "\n",
        "import os\n",
        "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   \n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torch.nn.parameter import Parameter\n",
        "import torchvision\n",
        "import numpy as np\n",
        "#from SpykeTorch import snn\n",
        "#from SpykeTorch import functional as sf\n",
        "#from SpykeTorch import visualization as vis\n",
        "#from SpykeTorch import utils\n",
        "from torchvision import transforms\n",
        "import struct\n",
        "import glob\n",
        "\n",
        "use_cuda = True\n",
        "\n",
        "class KheradpishehMNIST(nn.Module):\n",
        "\tdef __init__(self):\n",
        "\t\tsuper(KheradpishehMNIST, self).__init__()\n",
        "\n",
        "\t\tself.conv1 = Convolution(2, 32, 5, 0.8, 0.05) #snn  #2 to 3 because of num of channels\n",
        "\t\tself.conv1_t = 2 # num of classes\n",
        "\t\tself.k1 = 5\n",
        "\t\tself.r1 = 2\n",
        "\n",
        "\t\tself.conv2 = Convolution(32, 32, 2, 0.8, 0.05)  #snn\n",
        "\t\tself.conv2_t = 1\n",
        "\t\tself.k2 = 8\n",
        "\t\tself.r2 = 1\n",
        "\n",
        "\t\tself.stdp1 = STDP(self.conv1, (0.004, -0.003)) #snn\n",
        "\t\tself.stdp2 = STDP(self.conv2, (0.004, -0.003))  #snn\n",
        "\t\tself.max_ap = Parameter(torch.Tensor([0.15]))\n",
        "\n",
        "\t\tself.ctx = {\"input_spikes\":None, \"potentials\":None, \"output_spikes\":None, \"winners\":None}\n",
        "\t\tself.spk_cnt1 = 0\n",
        "\t\tself.spk_cnt2 = 0\n",
        "\t\n",
        "\tdef save_data(self, input_spike, potentials, output_spikes, winners):\n",
        "\t\tself.ctx[\"input_spikes\"] = input_spike\n",
        "\t\tself.ctx[\"potentials\"] = potentials\n",
        "\t\tself.ctx[\"output_spikes\"] = output_spikes\n",
        "\t\tself.ctx[\"winners\"] = winners\n",
        "\n",
        "\tdef forward(self, input, max_layer):\n",
        "\t\tinput = pad(input.float(), (2,2,2,2), 0)  #sf\n",
        "\t\tif self.training:\n",
        "\t\t\tpot = self.conv1(input)\n",
        "\t\t\tspk, pot = fire(pot, self.conv1_t, True) #sf\n",
        "\t\t\tif max_layer == 1:\n",
        "\t\t\t\tself.spk_cnt1 += 1\n",
        "\t\t\t\tif self.spk_cnt1 >= 500:\n",
        "\t\t\t\t\tself.spk_cnt1 = 0\n",
        "\t\t\t\t\tap = torch.tensor(self.stdp1.learning_rate[0][0].item(), device=self.stdp1.learning_rate[0][0].device) * 2\n",
        "\t\t\t\t\tap = torch.min(ap, self.max_ap)\n",
        "\t\t\t\t\tan = ap * -0.75\n",
        "\t\t\t\t\tself.stdp1.update_all_learning_rate(ap.item(), an.item())\n",
        "\t\t\t\tpot = pointwise_inhibition(pot) #sf\n",
        "\t\t\t\tspk = pot.sign()\n",
        "\t\t\t\twinners = get_k_winners(pot, self.k1, self.r1, spk) #sf\n",
        "\t\t\t\tself.save_data(input, pot, spk, winners)\n",
        "\t\t\t\treturn spk, pot\n",
        "\t\t\tspk_in = pad(pooling(spk, 2, 2, 1), (1,1,1,1)) #sf\n",
        "\t\t\tspk_in = pointwise_inhibition(spk_in)             #sf\n",
        "\t\t\tpot = self.conv2(spk_in)\n",
        "\t\t\tspk, pot = fire(pot, self.conv2_t, True)    #sf\n",
        "\t\t\tif max_layer == 2:\n",
        "\t\t\t\tpot = pointwise_inhibition(pot)  #sf\n",
        "\t\t\t\tspk = pot.sign()\n",
        "\t\t\t\twinners = get_k_winners(pot, self.k2, self.r2, spk) #sf\n",
        "\t\t\t\tself.save_data(spk_in, pot, spk, winners)\n",
        "\t\t\t\treturn spk, pot\n",
        "\t\t\tspk_out = pooling(spk, 2, 2, 1)  #sf\n",
        "\t\t\treturn spk_out\n",
        "\t\telse:\n",
        "\t\t\tpot = self.conv1(input)\n",
        "\t\t\tspk, pot = fire(pot, self.conv1_t, True)  #sf\n",
        "\t\t\tpot = self.conv2(pad(pooling(spk, 2, 2, 1), (1,1,1,1))) #sf\n",
        "\t\t\tspk, pot = fire(pot, self.conv2_t, True)  #sf\n",
        "\t\t\tspk = pooling(spk, 2, 2, 1)  #sf\n",
        "\t\t\treturn spk\n",
        "\t\n",
        "\tdef stdp(self, layer_idx):\n",
        "\t\tif layer_idx == 1:\n",
        "\t\t\tself.stdp1(self.ctx[\"input_spikes\"], self.ctx[\"potentials\"], self.ctx[\"output_spikes\"], self.ctx[\"winners\"])\n",
        "\t\tif layer_idx == 2:\n",
        "\t\t\tself.stdp2(self.ctx[\"input_spikes\"], self.ctx[\"potentials\"], self.ctx[\"output_spikes\"], self.ctx[\"winners\"])\n",
        "\n",
        "def train_unsupervise(network, data, layer_idx):\n",
        "\tnetwork.train()\n",
        "\tfor i in range(len(data)):\n",
        "\t\tdata_in = data[i]\n",
        "\t\tif use_cuda:\n",
        "\t\t\tdata_in = data_in.cuda()\n",
        "\t\tnetwork(data_in, layer_idx)\n",
        "\t\tnetwork.stdp(layer_idx)\n",
        "\n",
        "def test(network, data, target, layer_idx):\n",
        "\tnetwork.eval()\n",
        "\tans = [None] * len(data)\n",
        "\tt = [None] * len(data)\n",
        "\tfor i in range(len(data)):\n",
        "\t\tdata_in = data[i]\n",
        "\t\tif use_cuda:\n",
        "\t\t\tdata_in = data_in.cuda()\n",
        "\t\toutput,_ = network(data_in, layer_idx).max(dim = 0)\n",
        "\t\tans[i] = output.reshape(-1).cpu().numpy()\n",
        "\t\tt[i] = target[i]\n",
        "\treturn np.array(ans), np.array(t)\n",
        " \n",
        "class S1Transform:\n",
        "\tdef __init__(self, filter, timesteps = 15):\n",
        "\t\tself.grayscale = transforms.Grayscale()\n",
        "\t\tself.to_tensor = transforms.ToTensor()\n",
        "\t\tself.filter = filter\n",
        "\t\t#self.lateral_inhibition = lateral_inhibition\n",
        "\t\tself.temporal_transform = Intensity2Latency(timesteps)\n",
        "\t\t#self.feature_wise_inhibition = feature_wise_inhibition\n",
        "\tdef __call__(self, image):\n",
        "\t\timage = self.to_tensor(self.grayscale(image))*255\n",
        "\t\timage.unsqueeze_(0)\n",
        "\t\timage = self.filter(image)\n",
        "    #image = local_normalization(image,2)\n",
        "    #image = pooling(image, self.pooling_size, self.pooling_stride, padding=self.pooling_size//2)\n",
        "\t\ttemporal_image = self.temporal_transform(image)\n",
        "\t\treturn temporal_image.sign().byte()\n",
        "\n",
        "#class S1Transform:\n",
        "\t#def __init__(self, filter, timesteps = 15):\n",
        "   # self.grayscale = transforms.Grayscale()\n",
        "\t#\tself.to_tensor = transforms.ToTensor()\n",
        "\t#\tself.filter = filter\n",
        "\t#\tself.temporal_transform = Intensity2Latency(timesteps) #utils\n",
        "\t#\tself.cnt = 0\n",
        "\t#def __call__(self, image):\n",
        "    #image = self.to_tensor(self.grayscale(image))\n",
        "\t\t#if self.cnt % 1000 == 0:\n",
        "\t\t#\tprint(self.cnt)\n",
        "\t\t#self.cnt+=1\n",
        "\t\t#image = self.to_tensor(image) * 255\n",
        "\t\t#image.unsqueeze_(0)\n",
        "\t\t#image = self.filter(image)\n",
        "\t\t#image = local_normalization(image, 8) #sf\n",
        "\t\t#temporal_image = self.temporal_transform(image)\n",
        "\t\t#return temporal_image.sign().byte()\n",
        " \n",
        "kernels = [DoGKernel(7,3,2), #utils\n",
        "\t\t\t      DoGKernel(7,2,3)] #utils\n",
        "filter = Filter(kernels, padding = 3, thresholds = 50) #utils\n",
        "s1 = S1Transform(filter)\n",
        "data_root = \"data\"\n",
        "MNIST_train = CacheDataset(ImageFolder(\"/content/drive/MyDrive/final\", s1)) #utils\n",
        "MNIST_test = CacheDataset(ImageFolder(\"/content/drive/MyDrive/final\", s1)) #utils\n",
        "MNIST_loader = DataLoader(MNIST_train, batch_size=len(MNIST_train), shuffle=False) \n",
        "MNIST_testLoader = DataLoader(MNIST_test, batch_size=len(MNIST_test), shuffle=False)\n",
        "print(MNIST_train)\n",
        "print(MNIST_test)\n",
        "\n",
        "kheradpisheh = KheradpishehMNIST()\n",
        "if use_cuda:\n",
        "\tkheradpisheh.cuda()\n",
        "\n",
        "# Training The First Layer\n",
        "print(\"Training the first layer\")\n",
        "if os.path.isfile(\"saved_l1.net\"):\n",
        "\tkheradpisheh.load_state_dict(torch.load(\"saved_l1.net\"))\n",
        "else:\n",
        "\tfor epoch in range(2):\n",
        "\t\tprint(\"Epoch\", epoch)\n",
        "\t\titer = 0\n",
        "\t\tfor data,_ in MNIST_loader:\n",
        "\t\t\tprint(\"Iteration\", iter)\n",
        "\t\t\ttrain_unsupervise(kheradpisheh, data, 2) #1-->2\n",
        "\t\t\tprint(\"Done!\")\n",
        "\t\t\titer+=1\n",
        "\ttorch.save(kheradpisheh.state_dict(), \"saved_l1.net\")\n",
        "\n",
        "# Training The Second Layer\n",
        "print(\"Training the second layer\")\n",
        "if os.path.isfile(\"saved_l2.net\"):\n",
        "\tkheradpisheh.load_state_dict(torch.load(\"saved_l2.net\"))\n",
        "for epoch in range(20):\n",
        "\tprint(\"Epoch\", epoch)\n",
        "\titer = 0\n",
        "\tfor data,_ in MNIST_loader:\n",
        "\t\tprint(\"Iteration\", iter)\n",
        "\t\ttrain_unsupervise(kheradpisheh, data, 2)\n",
        "\t\tprint(\"Done!\")\n",
        "\t\titer+=1\n",
        "torch.save(kheradpisheh.state_dict(), \"saved_l2.net\")\n",
        "\n",
        "# Classification\n",
        "# Get train data\n",
        "for data,target in MNIST_loader:\n",
        "\ttrain_X, train_y = test(kheradpisheh, data, target, 2)\n",
        "\n",
        "print(train_X)\n",
        "print(train_X.shape)\t\n",
        "print(train_y)\n",
        "print(train_y.shape)\n",
        "\n",
        "# Get test data\n",
        "for data,target in MNIST_testLoader:\n",
        "\ttest_X, test_y = test(kheradpisheh, data, target, 2)\n",
        " \n",
        "print(test_X)\n",
        "print(test_X.shape)\t\n",
        "print(test_y)\n",
        "print(test_y.shape)\n",
        "\n",
        "# SVM\n",
        "from sklearn.svm import LinearSVC\n",
        "clf = LinearSVC(C=2.4)\n",
        "clf.fit(train_X, train_y)\n",
        "predict_train = clf.predict(train_X)\n",
        "predict_test = clf.predict(test_X)\n",
        "\n",
        "def get_performance(X, y, predictions):\n",
        "\tcorrect = 0\n",
        "\tsilence = 0\n",
        "\tfor i in range(len(predictions)):\n",
        "\t\tif X[i].sum() == 0:\n",
        "\t\t\tsilence += 1\n",
        "\t\telse:\n",
        "\t\t\tif predictions[i] == y[i]:\n",
        "\t\t\t\tcorrect += 1\n",
        "\treturn (correct/len(X), (len(X)-(correct+silence))/len(X), silence/len(X))\n",
        "\n",
        "print(get_performance(train_X, train_y, predict_train))\n",
        "print(get_performance(test_X, test_y, predict_test))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<__main__.CacheDataset object at 0x7fd0ea994550>\n",
            "<__main__.CacheDataset object at 0x7fd0a7bf0390>\n",
            "Training the first layer\n",
            "Epoch 0\n",
            "Iteration 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
            "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Done!\n",
            "Epoch 1\n",
            "Iteration 0\n",
            "Done!\n",
            "Training the second layer\n",
            "Epoch 0\n",
            "Iteration 0\n",
            "Done!\n",
            "Epoch 1\n",
            "Iteration 0\n",
            "Done!\n",
            "Epoch 2\n",
            "Iteration 0\n",
            "Done!\n",
            "Epoch 3\n",
            "Iteration 0\n",
            "Done!\n",
            "Epoch 4\n",
            "Iteration 0\n",
            "Done!\n",
            "Epoch 5\n",
            "Iteration 0\n",
            "Done!\n",
            "Epoch 6\n",
            "Iteration 0\n",
            "Done!\n",
            "Epoch 7\n",
            "Iteration 0\n",
            "Done!\n",
            "Epoch 8\n",
            "Iteration 0\n",
            "Done!\n",
            "Epoch 9\n",
            "Iteration 0\n",
            "Done!\n",
            "Epoch 10\n",
            "Iteration 0\n",
            "Done!\n",
            "Epoch 11\n",
            "Iteration 0\n",
            "Done!\n",
            "Epoch 12\n",
            "Iteration 0\n",
            "Done!\n",
            "Epoch 13\n",
            "Iteration 0\n",
            "Done!\n",
            "Epoch 14\n",
            "Iteration 0\n",
            "Done!\n",
            "Epoch 15\n",
            "Iteration 0\n",
            "Done!\n",
            "Epoch 16\n",
            "Iteration 0\n",
            "Done!\n",
            "Epoch 17\n",
            "Iteration 0\n",
            "Done!\n",
            "Epoch 18\n",
            "Iteration 0\n",
            "Done!\n",
            "Epoch 19\n",
            "Iteration 0\n",
            "Done!\n",
            "[[1. 1. 1. ... 1. 1. 1.]\n",
            " [1. 1. 1. ... 1. 1. 1.]\n",
            " [1. 1. 1. ... 1. 1. 1.]\n",
            " ...\n",
            " [1. 1. 1. ... 1. 1. 1.]\n",
            " [1. 1. 1. ... 1. 1. 1.]\n",
            " [1. 1. 1. ... 1. 1. 1.]]\n",
            "(871, 139392)\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "(871,)\n",
            "[[1. 1. 1. ... 1. 1. 1.]\n",
            " [1. 1. 1. ... 1. 1. 1.]\n",
            " [1. 1. 1. ... 1. 1. 1.]\n",
            " ...\n",
            " [1. 1. 1. ... 1. 1. 1.]\n",
            " [1. 1. 1. ... 1. 1. 1.]\n",
            " [1. 1. 1. ... 1. 1. 1.]]\n",
            "(871, 139392)\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "(871,)\n",
            "(1.0, 0.0, 0.0)\n",
            "(1.0, 0.0, 0.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dlqcMP4MBNs4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "56ced275-ed70-46e7-e564-fcdb8bacb319"
      },
      "source": [
        "import numpy as np\n",
        "import scipy.io\n",
        "from google.colab import files\n",
        "#print(np.mean(train_X[1]))\n",
        "#print(np.mean(train_X[600]))\n",
        "first=train_X[1]\n",
        "scipy.io.savemat('first.mat',{'first':first})\n",
        "files.download('first.mat')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_bdee4ea8-2021-4265-8689-559bffad13d2\", \"first.mat\", 557760)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "vb-rCYFfDRe1",
        "outputId": "6a412eae-70d3-4323-ee29-190effc48a58"
      },
      "source": [
        "import numpy as np\n",
        "import scipy.io\n",
        "from google.colab import files\n",
        "second=train_X[600]\n",
        "scipy.io.savemat('second.mat',{'second':second})\n",
        "files.download('second.mat')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_42177c84-9cf9-4574-8875-e34da90785fd\", \"second.mat\", 557760)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}